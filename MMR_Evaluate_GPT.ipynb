{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN4MkZQRS5FxIu0JH70l44Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rj9Avn9M2k1s","executionInfo":{"status":"ok","timestamp":1736122485488,"user_tz":480,"elapsed":563267,"user":{"displayName":"Yiming Zhao","userId":"08058171463442527075"}},"outputId":"2e2cd3a4-47ff-4620-859d-9f83cf0f93ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","0.324\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import json\n","from openai import OpenAI\n","\n","# Initialize OpenAI client\n","client = OpenAI(api_key=\"xxxxxxx\")\n","\n","# Process the file\n","file_path = '/content/drive/My Drive/World Models/responses.json'\n","\n","def evaluate_with_gpt(problem):\n","    \"\"\"\n","    Use GPT-4 API to evaluate the correctness of the model's response.\n","    \"\"\"\n","    query = problem.get('query', '').strip()\n","    response = problem.get('response', '').strip()\n","    answer = problem.get('answer', '').strip()\n","    choices = problem.get('choices', None)\n","\n","    # Construct the prompt\n","    prompt = f\"\"\"\n","    Question: {query}\n","    Model's response: {response}\n","    Expected answer: {answer}\n","    \"\"\"\n","    if choices:\n","        prompt += f\"Choices: {', '.join(choices)}\\n\"\n","    prompt += \"Is the model's response correct? Please answer 'Yes' or 'No'.\"\n","\n","    try:\n","        # Send the prompt to GPT-4\n","        completion = client.chat.completions.create(\n","            model=\"gpt-4o-mini\",\n","            store=True,\n","            messages=[\n","                {\"role\": \"user\", \"content\": prompt}\n","            ]\n","        )\n","\n","        # Extract the GPT-4 response\n","        gpt_response = completion.choices[0].message.content.strip()\n","        is_correct = gpt_response.lower() == 'yes'\n","        return is_correct, gpt_response\n","    except Exception as e:\n","        print(f\"Error evaluating problem {problem.get('pid', 'unknown')}: {e}\")\n","        return False, \"Error\"\n","\n","def process_responses_with_gpt(file_path):\n","    \"\"\"\n","    Process the responses in the given JSON file using GPT-4 for evaluation.\n","    Process all available samples.\n","    \"\"\"\n","    with open(file_path, 'r') as f:\n","        data = json.load(f)\n","\n","    total = len(data)\n","    correct = 0\n","    detailed_results = []\n","\n","    for pid, problem in data.items():\n","        is_correct, gpt_response = evaluate_with_gpt(problem)\n","        if is_correct:\n","            correct += 1\n","        detailed_results.append({\n","            'pid': pid,\n","            'query': problem.get('query', ''),\n","            'response': problem.get('response', ''),\n","            'answer': problem.get('answer', ''),\n","            'gpt_response': gpt_response,\n","            'is_correct': is_correct\n","        })\n","\n","    accuracy = correct / total if total > 0 else 0\n","\n","    return {\n","        'total': total,\n","        'correct': correct,\n","        'accuracy': accuracy,\n","        'detailed_results': detailed_results\n","    }\n","\n","# Re-run evaluation with GPT-4\n","results_with_gpt = process_responses_with_gpt(file_path)\n","\n","# Output results\n","import pprint\n","pprint.pprint(results_with_gpt['accuracy'])  # Print accuracy\n","\n","# Save detailed results to a file for further analysis\n","with open('/content/drive/My Drive/World Models/detailed_results_gpt.json', 'w') as f:\n","    json.dump(results_with_gpt['detailed_results'], f, indent=2)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"P6wwNJ2F_7bK"},"execution_count":null,"outputs":[]}]}